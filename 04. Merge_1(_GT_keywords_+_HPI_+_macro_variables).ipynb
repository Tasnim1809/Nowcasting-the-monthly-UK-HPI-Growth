{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook cleans and merges the regional UK HPI dataset with the 8 macroeconomic indicators and Google Trends indices. The link to each of the datasets can be found here:\n",
        "1. HPI: https://drive.google.com/file/d/1zTPNSV2soU48ksW86vaEVD4nzVzXnHz1/view?usp=sharing\n",
        "2. Average Earnings: https://drive.google.com/file/d/1Yc-3Zyomyav2_dg6CMEA52f4w6XDAhSn/view?usp=sharing\n",
        "3. CPI: https://drive.google.com/file/d/1j4I80vJvqcB_BusUaUhk5G0M08i-JZJZ/view?usp=sharing\n",
        "4. Unemployment Rate: https://drive.google.com/file/d/1SowP8X87_dsjVl_379eO8D49tGAxQs_l/view?usp=sharing\n",
        "5. Bank Rate: https://drive.google.com/file/d/1CQy4uyLEFJhXpOp3PsxNqukGW2YIgHKR/view?usp=sharing\n",
        "6. Mortgage Rate: https://drive.google.com/file/d/16zJaQ-vCZ5PJ3JHoIG0bQbeGmOgYa_sZ/view?usp=sharing\n",
        "7. Mortgage Approval: https://drive.google.com/file/d/1LMjfa5Rx3p-ERMm65nvsQlNhSNTwzb-C/view?usp=sharing\n",
        "8. Consumer Confidence Index: https://drive.google.com/file/d/1_7l8sQVxRFcxUTR1_PG1FzCoL9HsXeG0/view?usp=sharing\n",
        "9. Construction Cost Index: https://drive.google.com/file/d/1wEoM0Ub7QzAHBVg94t3Y6btxchZKtA85/view?usp=sharing\n",
        "10. Google Trend indices: https://drive.google.com/file/d/1sDR65v62YxxgPUVbcRtRcCRRVBn2TLmu/view?usp=sharing"
      ],
      "metadata": {
        "id": "PAlpPQ_Rj7SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging HPI (regional) + macro series + Google Trends\n",
        "!pip -q install XlsxWriter\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from functools import reduce\n",
        "\n",
        "\n",
        "# Defining base directories\n",
        "\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/Datasets\")\n",
        "OUT_DIR  = BASE_DIR / \"MERGED_OUTPUTS\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Finding the files by partial filename\n",
        "\n",
        "def find_file(*fragments):\n",
        "    fragments = [f.lower() for f in fragments]\n",
        "    for path in BASE_DIR.iterdir():\n",
        "        if path.is_file() and all(f in path.stem.lower() for f in fragments):\n",
        "            return path\n",
        "    raise FileNotFoundError(f\"Required file not found for fragments: {fragments}\")\n",
        "\n",
        "\n",
        "# Finding all required datasets\n",
        "\n",
        "paths = {\n",
        "    \"HPI\"      : find_file(\"hpi_clean_panel\"),\n",
        "    \"AWE\"      : find_file(\"averageearnings_monthly_cleaned_2005_2025\"),\n",
        "    \"UNEMP\"    : find_file(\"unemploymentrate_monthly_cleaned_2005_2025\"),\n",
        "    \"CPI\"      : find_file(\"cpi_monthly_cleaned_2005_2025\"),\n",
        "    \"APPR\"     : find_file(\"mortgageapprovals_monthly_cleaned_2005_2025\"),\n",
        "    \"MORT2Y\"   : find_file(\"mortgagerate_monthly_cleaned_2005_2025\"),\n",
        "    \"BANKRATE\" : find_file(\"bankrate_monthly_cleaned_2005_2025\"),\n",
        "    \"CONF\"     : find_file(\"ConsumerConfidence_monthly_cleaned_2005_2025_modified\"),\n",
        "    \"CONST\"    : find_file(\"BuildingMaterials_monthly_cleaned_2005_2025\"),\n",
        "    \"TRENDS\"   : find_file(\"theme_trends_monthly_standardised_modified\"),\n",
        "}\n",
        "\n",
        "\n",
        "def read_any(path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Read CSV or Excel with encoding fallback.\"\"\"\n",
        "    if path.suffix.lower() in (\".xlsx\", \".xls\"):\n",
        "        return pd.read_excel(path)\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except UnicodeDecodeError:\n",
        "        return pd.read_csv(path, encoding=\"latin1\")\n",
        "\n",
        "def to_month_start_mdy(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"Parse MDY dates and align to month start.\"\"\"\n",
        "    return (\n",
        "        pd.to_datetime(series, errors=\"coerce\", dayfirst=False)\n",
        "          .dt.to_period(\"M\")\n",
        "          .dt.to_timestamp(how=\"start\")\n",
        "    )\n",
        "\n",
        "def clean_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Strip %, commas, and coerce all non-Date columns to numeric.\"\"\"\n",
        "    for col in df.columns:\n",
        "        if col == \"Date\":\n",
        "            continue\n",
        "        df[col] = (\n",
        "            df[col].astype(str)\n",
        "                  .str.replace(\"%\", \"\", regex=False)\n",
        "                  .str.replace(\",\", \"\", regex=False)\n",
        "                  .str.extract(r\"([-+]?\\d*\\.?\\d+)\")[0]\n",
        "                  .astype(float)\n",
        "        )\n",
        "    return df\n",
        "\n",
        "def load_macro_series(path: Path, rename=None, prefix=None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load a monthly macro series:\n",
        "    - Parse MDY dates\n",
        "    - Clean numerics\n",
        "    - Deduplicate to one observation per month\n",
        "    \"\"\"\n",
        "    df = read_any(path).copy()\n",
        "\n",
        "    date_col = \"Date\" if \"Date\" in df.columns else df.columns[0]\n",
        "    df[\"Date\"] = to_month_start_mdy(df[date_col])\n",
        "    df = df.dropna(subset=[\"Date\"])\n",
        "\n",
        "    # Removing redundant year/month columns\n",
        "    df = df.drop(columns=[c for c in df.columns if c.lower() in (\"year\", \"month\") and c != \"Date\"],\n",
        "                 errors=\"ignore\")\n",
        "\n",
        "    df = df[[\"Date\"] + [c for c in df.columns if c != \"Date\"]]\n",
        "    df = clean_numeric(df)\n",
        "\n",
        "    if rename:\n",
        "        df = df.rename(columns=rename)\n",
        "    if prefix:\n",
        "        df = df.rename(columns={c: f\"{prefix}{c}\" for c in df.columns if c != \"Date\"})\n",
        "\n",
        "    return (\n",
        "        df.sort_values(\"Date\")\n",
        "          .groupby(\"Date\", as_index=False)\n",
        "          .agg({c: \"last\" for c in df.columns if c != \"Date\"})\n",
        "    )\n",
        "\n",
        "\n",
        "# Loading and standardising macroeconomic indicators\n",
        "\n",
        "awe   = load_macro_series(paths[\"AWE\"], {\n",
        "    \"TotalWeeklyEarnings\": \"AWE_Total\",\n",
        "    \"RegularWeeklyEarnings\": \"AWE_Regular\",\n",
        "    \"awe_total\": \"AWE_Total\",\n",
        "    \"awe_regular\": \"AWE_Regular\"\n",
        "})\n",
        "\n",
        "unemp = load_macro_series(paths[\"UNEMP\"], {\"UnemploymentRate\": \"UnemploymentRate\"})\n",
        "cpi   = load_macro_series(paths[\"CPI\"],   {\"CPI\": \"CPI\"})\n",
        "appr  = load_macro_series(paths[\"APPR\"],  {\"MortgageApprovals\": \"MortgageApprovals\"})\n",
        "mort2 = load_macro_series(paths[\"MORT2Y\"],{\"MortgageRate\": \"MortgageRate_2YFix\"})\n",
        "br    = load_macro_series(paths[\"BANKRATE\"], {\"BankRate\": \"BankRate\"})\n",
        "conf  = load_macro_series(paths[\"CONF\"], {\"ConsumerConfidence\": \"ConsumerConfidence\"})\n",
        "const = load_macro_series(paths[\"CONST\"], prefix=\"BM_\")\n",
        "\n",
        "# Google Trends theme indices\n",
        "trends = load_macro_series(paths[\"TRENDS\"])\n",
        "trends = trends.rename(\n",
        "    columns={c: (c if c.lower().startswith(\"gt_\") else f\"gt_{c}\")\n",
        "             for c in trends.columns if c != \"Date\"}\n",
        ")\n",
        "\n",
        "# Merging all macro series by month\n",
        "macro = reduce(lambda l, r: pd.merge(l, r, on=\"Date\", how=\"outer\"),\n",
        "               [awe, unemp, cpi, appr, mort2, br, conf, const, trends])\n",
        "\n",
        "\n",
        "# Loading and preparing regional HPI data\n",
        "\n",
        "hpi_raw = read_any(paths[\"HPI\"]).copy()\n",
        "\n",
        "if \"Date\" not in hpi_raw.columns:\n",
        "    raise ValueError(\"HPI dataset must contain a 'Date' column.\")\n",
        "\n",
        "hpi_raw[\"Date\"] = to_month_start_mdy(hpi_raw[\"Date\"])\n",
        "\n",
        "# Normalising region identifiers\n",
        "for col in hpi_raw.columns:\n",
        "    cl = col.lower()\n",
        "    if \"region\" in cl and \"name\" in cl and \"RegionName\" not in hpi_raw.columns:\n",
        "        hpi_raw = hpi_raw.rename(columns={col: \"RegionName\"})\n",
        "    if cl in (\"areacode\", \"area_code\", \"code\") and \"AreaCode\" not in hpi_raw.columns:\n",
        "        hpi_raw = hpi_raw.rename(columns={col: \"AreaCode\"})\n",
        "\n",
        "keep_cols = [c for c in [\"Date\", \"RegionName\", \"AreaCode\",\n",
        "                         \"AveragePrice\", \"Index\", \"SalesVolume\"]\n",
        "             if c in hpi_raw.columns]\n",
        "\n",
        "hpi = hpi_raw[keep_cols].sort_values([\"RegionName\", \"Date\"])\n",
        "\n",
        "\n",
        "# Filtering for the study window and merging regional HPI with macro data\n",
        "\n",
        "START, END = pd.Timestamp(2005, 1, 1), pd.Timestamp(2025, 6, 1)\n",
        "\n",
        "macro = macro[(macro[\"Date\"] >= START) & (macro[\"Date\"] <= END)]\n",
        "hpi   = hpi[(hpi[\"Date\"]   >= START) & (hpi[\"Date\"]   <= END)]\n",
        "\n",
        "hpi_regional = pd.merge(hpi, macro, on=\"Date\", how=\"left\", validate=\"m:1\")\n",
        "\n",
        "\n",
        "# Save outputs\n",
        "\n",
        "xlsx_path = OUT_DIR / \"HPI_regional_merged_2005_2025_ddmmyyyy_MODIFIED.xlsx\"\n",
        "csv_path  = OUT_DIR / \"HPI_regional_merged_2005_2025_ddmmyyyy_MODIFIED.csv\"\n",
        "\n",
        "with pd.ExcelWriter(xlsx_path, engine=\"xlsxwriter\", datetime_format=\"dd/mm/yyyy\") as writer:\n",
        "    hpi_regional.to_excel(writer, index=False, sheet_name=\"HPI_Regional\")\n",
        "    worksheet = writer.sheets[\"HPI_Regional\"]\n",
        "    workbook  = writer.book\n",
        "    worksheet.set_column(\n",
        "        hpi_regional.columns.get_loc(\"Date\"),\n",
        "        hpi_regional.columns.get_loc(\"Date\"),\n",
        "        12,\n",
        "        workbook.add_format({\"num_format\": \"dd/mm/yyyy\"})\n",
        "    )\n",
        "\n",
        "csv_tmp = hpi_regional.copy()\n",
        "csv_tmp[\"Date\"] = csv_tmp[\"Date\"].dt.strftime(\"%d/%m/%Y\")\n",
        "csv_tmp.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"Saved Excel:\", xlsx_path)\n",
        "print(\"Saved CSV  :\", csv_path)\n",
        "files.download(str(xlsx_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "3P6F7b1Yj54R",
        "outputId": "a3552a1f-c287-4ae1-c187-2766c5c5b047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Saved Excel: /content/drive/MyDrive/Datasets/MERGED_OUTPUTS/HPI_regional_merged_2005_2025_ddmmyyyy_MODIFIED.xlsx\n",
            "Saved CSV  : /content/drive/MyDrive/Datasets/MERGED_OUTPUTS/HPI_regional_merged_2005_2025_ddmmyyyy_MODIFIED.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_39b1d58c-8262-444e-9e01-84183a09f6a6\", \"HPI_regional_merged_2005_2025_ddmmyyyy_MODIFIED.xlsx\", 13751453)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}